{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "resident-orleans",
   "metadata": {},
   "source": [
    "# Implementation examples for different usages of CARLA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-gasoline",
   "metadata": {},
   "source": [
    "## CARLA as recourse library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-brake",
   "metadata": {},
   "source": [
    "In the following cell we show how to use CARLA with our catalog black-box-models and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "experimental-happening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\eigene dateien\\uni\\master\\4_semester_ss21\\masterarbeit\\gitroot\\carla\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From d:\\eigene dateien\\uni\\master\\4_semester_ss21\\masterarbeit\\gitroot\\carla\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "        age    fnlwgt  education-num  capital-gain  capital-loss  ...  \\\n",
      "0  0.301370  0.011804       0.842736      0.068822     -0.015151  ...   \n",
      "1  0.452055  0.054399       0.756822      0.051798      0.021260  ...   \n",
      "2  0.287671  0.109978       0.548728      0.098452      0.051220  ...   \n",
      "3  0.493151  0.091310       0.480278      0.045284      0.047023  ...   \n",
      "4  0.150685  0.215607       0.808901      0.006013      0.004227  ...   \n",
      "\n",
      "   relationship_Non-Husband  race_White  sex_Male  native-country_US  income  \n",
      "0                       1.0         1.0       1.0                1.0     1.0  \n",
      "1                       0.0         1.0       1.0                1.0     1.0  \n",
      "2                       1.0         1.0       1.0                1.0     1.0  \n",
      "3                       0.0         0.0       1.0                1.0     1.0  \n",
      "4                       1.0         0.0       0.0                0.0     1.0  \n",
      "\n",
      "[5 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "from carla import DataCatalog, MLModelCatalog\n",
    "from carla.recourse_methods import GrowingSpheres\n",
    "\n",
    "# load catalog dataset\n",
    "data_name = \"adult\"\n",
    "dataset = DataCatalog(data_name)\n",
    "\n",
    "# load artificial neural network from catalog\n",
    "model = MLModelCatalog(dataset, \"ann\")\n",
    "\n",
    "# get some factuals from the data to generate counterfactual examples\n",
    "factuals = dataset.raw.iloc[:10]\n",
    "\n",
    "# load recourse model with model specific hyperparameter\n",
    "gs = GrowingSpheres(model)\n",
    "\n",
    "# generate counterfactual examples\n",
    "counterfactuals = gs.get_counterfactuals(factuals)\n",
    "\n",
    "print(counterfactuals.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-convert",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If a user is interested in using its own black-box-model or dataset, we provide an easy-to-use interface in CARLA to\n",
    "wrap every possible model or dataset. Below we want to give a pseudo-code implementation of such an use-case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from carla import Data, MLModel\n",
    "from carla.recourse_methods import GrowingSpheres\n",
    "\n",
    "# first implement the dataset wrapper\n",
    "class MyOwnData(Data):\n",
    "    def __init__(self):\n",
    "        # the dataset could be loaded in the constructor\n",
    "        self._dataset = load_dataset_from_disk()\n",
    "\n",
    "    def categoricals(self):\n",
    "        # this property contains a list of all categorical features\n",
    "        return [...]\n",
    "\n",
    "    def continous(self):\n",
    "        # this property contains a list of all continuous features\n",
    "        return [...]\n",
    "\n",
    "    def immutables(self):\n",
    "        # this property contains a list of features which should not be changed by the recourse method\n",
    "        return [...]\n",
    "\n",
    "    def target(self):\n",
    "        # this property contains the feature name of the target column\n",
    "        return \"label\"\n",
    "\n",
    "    def raw(self):\n",
    "        # this property contains the not encoded and not normalized, raw dataset\n",
    "        return self._dataset\n",
    "\n",
    "# second, implement the black-box-model wrapper\n",
    "class MyOwnModel(MLModel):\n",
    "    def __init__(self, data):\n",
    "        super().__init__(data)\n",
    "        # the constructor can be used to load or build an arbitrary black-box-model\n",
    "        self._mymodel = load_model()\n",
    "\n",
    "        # this property contains a fitted scaler to normalize input data\n",
    "        # MinMaxScaler from sklearn is predefined, but can be redefined by every other sklearn scaler\n",
    "        self.scaler = MySklearnScaler().fit()\n",
    "\n",
    "        # the same is possible for data encoding\n",
    "        # OneHotEncoder from sklearn with dropped first column for binary data is predefined, but can be\n",
    "        # changed into any other sklearn encoder.\n",
    "        self.encoder = MySklearnEncoder.fit()\n",
    "\n",
    "    def feature_input_order(self):\n",
    "        # this property contains a list of the correct input order of features for the ml model\n",
    "        return [...]\n",
    "\n",
    "    def backend(self):\n",
    "        # this property contains a string with the used backend of the model\n",
    "        return \"pytorch\"\n",
    "\n",
    "    def raw_model(self):\n",
    "        # this property contains the fitted/ loaded black-box-model\n",
    "        return self._mymodel\n",
    "\n",
    "    def predict(self, x: Union[np.ndarray, pd.DataFrame]):\n",
    "        # the predict function outputs the continous prediction of the model, similar to sklearn.\n",
    "        return self._mymodel.predict(x)\n",
    "\n",
    "    def predict_proba(self, x: Union[np.ndarray, pd.DataFrame]):\n",
    "        # the predict_proba method outputs the prediction as class probabilities, similar to sklearn\n",
    "        return self._mymodel.predict_proba(x)\n",
    "\n",
    "\n",
    "# after implementing the user-specific model and dataset, the call of the recourse method,\n",
    "# and the generation of counterfactuals stays the same.\n",
    "dataset = MyOwnData()\n",
    "model = MyOwnModel(dataset)\n",
    "\n",
    "# get some factuals from the data to generate counterfactual examples\n",
    "factuals = dataset.raw.iloc[:10]\n",
    "\n",
    "# load recourse model with model specific hyperparameter\n",
    "gs = GrowingSpheres(model)\n",
    "\n",
    "# generate counterfactual examples\n",
    "counterfactuals = gs.get_counterfactuals(factuals)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CARLA for research groups\n",
    "\n",
    "New recourse methods can be implemented via a simple interface to benchmark new methods with already existing ones.\n",
    "The following example shows a pseudo-code example of how to integrate new recourse methods into CARLA."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from carla import RecourseMethod\n",
    "\n",
    "# similar to data- and model wrapper, call the recourse method wrapper\n",
    "class MyRecourseMethod(RecourseMethod):\n",
    "    def __init__(self, mlmodel):\n",
    "        super().__init__(mlmodel)\n",
    "        # the constructor can be used to load the recourse method,\n",
    "        # or construct everything necessary\n",
    "\n",
    "    def get_counterfactuals(self, factuals: pd.DataFrame):\n",
    "        # this property is responsible to generate and output\n",
    "        # encoded and scaled counterfactual examples\n",
    "        # as pandas DataFrames\n",
    "        return counterfactual_examples\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benchmarking recourse methods\n",
    "\n",
    "The following will show a simple way to use the Benchmarking-class for every wrapped recourse method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from carla import Benchmark\n",
    "\n",
    "# first initilize the benchmarking class by passing\n",
    "# black-box-model, recourse method, and factuals into it\n",
    "benchmark = Benchmark(model, gs, factuals)\n",
    "\n",
    "# now you can decide if you want to run all measurements\n",
    "# or just specific ones.\n",
    "\n",
    "# lets first compute the distance measure\n",
    "distances = benchmark.compute_distances()\n",
    "\n",
    "# now run all implemented measurements and create a\n",
    "# DataFrame which consists of all results\n",
    "results = benchmark.run_benchmark()\n",
    "\n",
    "print(results.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Distance_1  Distance_2  Distance_3  Distance_4  Constraint_Violation  \\\n",
      "0         6.0    1.118620    1.003804         1.0                     1   \n",
      "1         6.0    1.198937    1.008668         1.0                     0   \n",
      "2         6.0    1.415906    1.037730         1.0                     0   \n",
      "3         6.0    1.233176    1.011142         1.0                     0   \n",
      "4         6.0    1.052909    1.000734         1.0                     0   \n",
      "\n",
      "   Redundancy  y-Nearest-Neighbours  Success_Rate  Average_Time  \n",
      "0           4              0.285714           0.7      0.011632  \n",
      "1           4                   NaN           NaN           NaN  \n",
      "2           3                   NaN           NaN           NaN  \n",
      "3           4                   NaN           NaN           NaN  \n",
      "4           4                   NaN           NaN           NaN  \n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
