{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Surfer\\Desktop\\EaFML Project\\CARLA\n"
     ]
    }
   ],
   "source": [
    "# If running this notebook without having carla installed\n",
    "%cd ..\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n"
     ]
    }
   ],
   "source": [
    "import carla\n",
    "from carla import logging\n",
    "logger = carla.get_logger(\"carla\")\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from carla.data.catalog import OnlineCatalog\n",
    "import carla.evaluation.catalog as evaluation_catalog\n",
    "from carla.models.catalog import MLModelCatalog\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "from carla.models.negative_instances import predict_negative_instances\n",
    "from carla.recourse_methods.processing import reconstruct_encoding_constraints\n",
    "from carla import Benchmark\n",
    "from carla.recourse_methods.catalog.arar import ARAR\n",
    "from carla.models import MLModel\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Adult dataset with ANN model and ARAR recourse method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data_name = \"adult\"\n",
    "dataset = OnlineCatalog(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load catalog model\n",
    "model_type = \"ann\"\n",
    "ml_model = MLModelCatalog(\n",
    "    dataset,\n",
    "    model_type=model_type,\n",
    "    load_online=True,\n",
    "    backend=\"pytorch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the standard hyperparameters\n",
    "hyperparams = None\n",
    "recourse_method = recourse_catalog.ARAR(ml_model, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.821 Lambda: 0.0000: 100%|██████████| 100/100 [01:49<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "factuals = factuals\n",
    "\n",
    "counterfactuals = recourse_method.get_counterfactuals(factuals)\n",
    "counterfactuals = counterfactuals.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>...</th>\n",
       "      <th>occupation_Other</th>\n",
       "      <th>relationship_Non-Husband</th>\n",
       "      <th>race_White</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>native-country_US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.578932</td>\n",
       "      <td>0.231562</td>\n",
       "      <td>0.633211</td>\n",
       "      <td>0.099966</td>\n",
       "      <td>0.099824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.414448</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.766521</td>\n",
       "      <td>0.099960</td>\n",
       "      <td>0.099790</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.455626</td>\n",
       "      <td>0.168843</td>\n",
       "      <td>0.499874</td>\n",
       "      <td>0.099965</td>\n",
       "      <td>0.568596</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.606340</td>\n",
       "      <td>0.211692</td>\n",
       "      <td>0.699880</td>\n",
       "      <td>0.099967</td>\n",
       "      <td>0.099828</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.195398</td>\n",
       "      <td>0.206866</td>\n",
       "      <td>0.899884</td>\n",
       "      <td>0.099968</td>\n",
       "      <td>0.099833</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40277</th>\n",
       "      <td>0.304893</td>\n",
       "      <td>0.254743</td>\n",
       "      <td>0.499862</td>\n",
       "      <td>0.099962</td>\n",
       "      <td>0.483640</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40284</th>\n",
       "      <td>0.578920</td>\n",
       "      <td>0.251961</td>\n",
       "      <td>0.633190</td>\n",
       "      <td>0.099961</td>\n",
       "      <td>0.099776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40302</th>\n",
       "      <td>0.537853</td>\n",
       "      <td>0.141497</td>\n",
       "      <td>0.633197</td>\n",
       "      <td>0.099964</td>\n",
       "      <td>0.099789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40316</th>\n",
       "      <td>0.524090</td>\n",
       "      <td>0.282756</td>\n",
       "      <td>0.633200</td>\n",
       "      <td>0.099963</td>\n",
       "      <td>0.099808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40317</th>\n",
       "      <td>0.702095</td>\n",
       "      <td>0.149948</td>\n",
       "      <td>0.633182</td>\n",
       "      <td>0.099958</td>\n",
       "      <td>0.099781</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7216 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education-num  capital-gain  capital-loss  ...  \\\n",
       "4      0.578932  0.231562       0.633211      0.099966      0.099824  ...   \n",
       "7      0.414448  0.171745       0.766521      0.099960      0.099790  ...   \n",
       "15     0.455626  0.168843       0.499874      0.099965      0.568596  ...   \n",
       "18     0.606340  0.211692       0.699880      0.099967      0.099828  ...   \n",
       "31     0.195398  0.206866       0.899884      0.099968      0.099833  ...   \n",
       "...         ...       ...            ...           ...           ...  ...   \n",
       "40277  0.304893  0.254743       0.499862      0.099962      0.483640  ...   \n",
       "40284  0.578920  0.251961       0.633190      0.099961      0.099776  ...   \n",
       "40302  0.537853  0.141497       0.633197      0.099964      0.099789  ...   \n",
       "40316  0.524090  0.282756       0.633200      0.099963      0.099808  ...   \n",
       "40317  0.702095  0.149948       0.633182      0.099958      0.099781  ...   \n",
       "\n",
       "       occupation_Other  relationship_Non-Husband  race_White  sex_Male  \\\n",
       "4                   0.0                       0.0         1.0       1.0   \n",
       "7                   1.0                       0.0         0.0       1.0   \n",
       "15                  1.0                       0.0         1.0       1.0   \n",
       "18                  1.0                       0.0         0.0       1.0   \n",
       "31                  1.0                       0.0         1.0       1.0   \n",
       "...                 ...                       ...         ...       ...   \n",
       "40277               1.0                       0.0         1.0       1.0   \n",
       "40284               0.0                       1.0         1.0       0.0   \n",
       "40302               0.0                       0.0         1.0       1.0   \n",
       "40316               0.0                       0.0         1.0       1.0   \n",
       "40317               1.0                       0.0         1.0       1.0   \n",
       "\n",
       "       native-country_US  \n",
       "4                    1.0  \n",
       "7                    1.0  \n",
       "15                   1.0  \n",
       "18                   0.0  \n",
       "31                   1.0  \n",
       "...                  ...  \n",
       "40277                1.0  \n",
       "40284                0.0  \n",
       "40302                0.0  \n",
       "40316                1.0  \n",
       "40317                1.0  \n",
       "\n",
       "[7216 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counterfactuals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: With hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {'lr': 0.01, 'epsilon': 0.05, 'outer_iters': 10, 'inner_iters': 50, 'inner_max_pgd':True}\n",
    "recourse_method = recourse_catalog.ARAR(ml_model, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.780 Lambda: 0.3487: 100%|██████████| 10/10 [00:16<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "factuals = factuals[:50]\n",
    "\n",
    "counterfactuals = recourse_method.get_counterfactuals(factuals)\n",
    "counterfactuals = counterfactuals.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing ARAR and Wachter: generating attacks on the counterfactuals in the epsilon ball via gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_generate_perturbations_gradient(model, counterfactuals, y_target = 1, epsilon = 0.05, binary_cat_features = True):\n",
    "    \"\"\" Generate adversarial perturbations on the data based on the gradient \"\"\"\n",
    "\n",
    "    factuals = model.get_ordered_features(counterfactuals)\n",
    "\n",
    "    encoded_feature_names = model.data.encoder.get_feature_names(\n",
    "        model.data.categorical\n",
    "    )\n",
    "    cat_features_indices = [\n",
    "        factuals.columns.get_loc(feature) for feature in encoded_feature_names\n",
    "    ]\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    x = torch.from_numpy(factuals.to_numpy().astype(np.float32)).to(device)\n",
    "    preds = model.predict(x)\n",
    "    #now pertubate the data\n",
    "    D = x.shape[1]\n",
    "    loss = torch.nn.BCEWithLogitsLoss(reduction='none')\n",
    "    target_vec = torch.ones(x.shape[0], device=device) * y_target\n",
    "    x_pertb = torch.autograd.Variable(torch.zeros(x.shape, device =device), requires_grad=True)\n",
    "    x_adv = x + x_pertb\n",
    "    loss_x = torch.mean(loss(model.predict(x_adv).squeeze(), target_vec))\n",
    "    grad = torch.autograd.grad(loss_x, x_pertb, create_graph=False)[0]\n",
    "    sum = torch.sum(grad, dim=-1)\n",
    "    pertb = grad\n",
    "    pertb[sum!=0] = pertb [sum!=0]/ torch.linalg.norm(grad[sum!=0], dim=-1, keepdims=True) * epsilon\n",
    "    x_pertb = x + pertb\n",
    "    x_pertb = reconstruct_encoding_constraints(x_pertb, cat_features_indices, binary_cat_features)\n",
    "    preds_pertb = model.predict(x_pertb)\n",
    "    return x_pertb.cpu().detach().numpy(), preds.cpu().detach().numpy(), preds_pertb.cpu().detach().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing ARAR and Wachter: generating random samples in the epsilon ball and classifying them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_generate_perturbations_random(model, counterfactuals, n_samples = 20, epsilon = 0.05, binary_cat_features = True):\n",
    "    \"\"\" Generates random sampels in the epsilon ball\"\"\"\n",
    "    factuals = model.get_ordered_features(counterfactuals)\n",
    "        \n",
    "    encoded_feature_names = model.data.encoder.get_feature_names(\n",
    "        model.data.categorical\n",
    "    )\n",
    "    cat_features_indices = [\n",
    "        factuals.columns.get_loc(feature) for feature in encoded_feature_names\n",
    "    ]\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    x = torch.from_numpy(factuals.to_numpy().astype(np.float32)).to(device)\n",
    "    pred_pertb_list = torch.zeros((n_samples, x.shape[0]), device=device)\n",
    "    for i in range(n_samples):\n",
    "        pertb = torch.randn(x.shape, device=device)\n",
    "        sum = torch.sum(pertb, dim=-1)\n",
    "        pertb[sum!=0] = pertb [sum!=0]/ torch.linalg.norm(pertb[sum!=0], dim=-1, keepdims=True) * epsilon\n",
    "        x_pertb = x + pertb\n",
    "        x_pertb = reconstruct_encoding_constraints(x_pertb, cat_features_indices, binary_cat_features)\n",
    "        preds_pertb = model.predict(x_pertb).squeeze()\n",
    "        pred_pertb_list[i] = preds_pertb>=0.5\n",
    "    pred_pertb_list = pred_pertb_list.cpu().numpy()\n",
    "    return np.mean(pred_pertb_list, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concise Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################################################################\n",
      "######### model_type:  ann\n",
      "#################################################################################################################\n",
      "###### Dataset Name:  adult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.993 Lambda: 0.0000: 100%|██████████| 100/100 [01:45<00:00,  1.06s/it]\n",
      "Pct left: 0.993 Lambda: 0.0000: 100%|██████████| 100/100 [10:23<00:00,  6.24s/it]\n",
      "Pct left: 0.821 Lambda: 0.0000: 100%|██████████| 100/100 [01:46<00:00,  1.06s/it]\n",
      "Pct left: 0.821 Lambda: 0.0000: 100%|██████████| 100/100 [10:18<00:00,  6.18s/it]\n",
      "Pct left: 0.613 Lambda: 0.0000: 100%|██████████| 100/100 [01:44<00:00,  1.05s/it]\n",
      "Pct left: 0.613 Lambda: 0.0000: 100%|██████████| 100/100 [01:45<00:00,  1.05s/it]\n",
      "100%|██████████| 500/500 [15:14<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  277  /  40325  =  0.006869187848729076\n",
      "ARAR, eps=0.1, pgd:  277  /  40325  =  0.006869187848729076\n",
      "ARAR, eps=0.05:  7216  /  40325  =  0.17894606323620582\n",
      "ARAR, eps=0.05, pgd:  7216  /  40325  =  0.17894606323620582\n",
      "ARAR, eps=0.0:  15621  /  40325  =  0.3873775573465592\n",
      "ARAR, eps=0.0, like Wachter:  15621  /  40325  =  0.3873775573465592\n",
      "Wachter:  203  /  500  =  0.406\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  1.0 1.0\n",
      "ARAR, eps=0.1, pgd:  1.0 1.0\n",
      "ARAR, eps=0.05:  1.0 0.9552383592017738\n",
      "ARAR, eps=0.05, pgd:  1.0 0.9552383592017738\n",
      "ARAR, eps=0.0:  1.0 0.5016964342871775\n",
      "ARAR, eps=0.0, like Wachter:  1.0 0.0\n",
      "Wachter:  1.0 0.0\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  1.0\n",
      "ARAR, eps=0.1, pgd:  1.0\n",
      "ARAR, eps=0.05:  0.9999962\n",
      "ARAR, eps=0.05, pgd:  0.999998\n",
      "ARAR, eps=0.0:  0.9906194\n",
      "ARAR, eps=0.0, like Wachter:  0.60618407\n",
      "Wachter:  0.59691626\n",
      "###### Dataset Name:  compas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.995 Lambda: 0.0000: 100%|██████████| 100/100 [00:31<00:00,  3.19it/s]\n",
      "Pct left: 0.995 Lambda: 0.0000: 100%|██████████| 100/100 [02:30<00:00,  1.51s/it]\n",
      "Pct left: 0.602 Lambda: 0.0000: 100%|██████████| 100/100 [00:31<00:00,  3.19it/s]\n",
      "Pct left: 0.602 Lambda: 0.0000: 100%|██████████| 100/100 [02:31<00:00,  1.52s/it]\n",
      "Pct left: 0.343 Lambda: 0.0000: 100%|██████████| 100/100 [00:32<00:00,  3.08it/s]\n",
      "Pct left: 0.343 Lambda: 0.0000: 100%|██████████| 100/100 [00:33<00:00,  2.98it/s]\n",
      "100%|██████████| 500/500 [07:07<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  4  /  800  =  0.005\n",
      "ARAR, eps=0.1, pgd:  4  /  800  =  0.005\n",
      "ARAR, eps=0.05:  318  /  800  =  0.3975\n",
      "ARAR, eps=0.05, pgd:  318  /  800  =  0.3975\n",
      "ARAR, eps=0.0:  526  /  800  =  0.6575\n",
      "ARAR, eps=0.0, like Wachter:  526  /  800  =  0.6575\n",
      "Wachter:  322  /  500  =  0.644\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  1.0 1.0\n",
      "ARAR, eps=0.1, pgd:  1.0 1.0\n",
      "ARAR, eps=0.05:  1.0 1.0\n",
      "ARAR, eps=0.05, pgd:  1.0 1.0\n",
      "ARAR, eps=0.0:  1.0 0.8992395437262357\n",
      "ARAR, eps=0.0, like Wachter:  1.0 0.0\n",
      "Wachter:  1.0 0.0\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  1.0\n",
      "ARAR, eps=0.1, pgd:  1.0\n",
      "ARAR, eps=0.05:  1.0\n",
      "ARAR, eps=0.05, pgd:  1.0\n",
      "ARAR, eps=0.0:  0.9997642\n",
      "ARAR, eps=0.0, like Wachter:  0.59002095\n",
      "Wachter:  0.5917857\n",
      "###### Dataset Name:  give_me_some_credit\n",
      "No test factuals classified as the negative instance were found -> skipping this evaluation\n",
      "###### Dataset Name:  heloc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 1.000 Lambda: 0.0000: 100%|██████████| 100/100 [00:38<00:00,  2.62it/s]\n",
      "Pct left: 1.000 Lambda: 0.0000: 100%|██████████| 100/100 [03:40<00:00,  2.20s/it]\n",
      "Pct left: 1.000 Lambda: 0.0000: 100%|██████████| 100/100 [00:38<00:00,  2.58it/s]\n",
      "Pct left: 1.000 Lambda: 0.0000: 100%|██████████| 100/100 [03:46<00:00,  2.26s/it]\n",
      "Pct left: 1.000 Lambda: 0.0000: 100%|██████████| 100/100 [00:39<00:00,  2.50it/s]\n",
      "Pct left: 1.000 Lambda: 0.0000: 100%|██████████| 100/100 [00:41<00:00,  2.40it/s]\n",
      "100%|██████████| 500/500 [15:36<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  0  /  9871  =  0.0\n",
      "ARAR, eps=0.1, pgd:  0  /  9871  =  0.0\n",
      "ARAR, eps=0.05:  0  /  9871  =  0.0\n",
      "ARAR, eps=0.05, pgd:  0  /  9871  =  0.0\n",
      "ARAR, eps=0.0:  0  /  9871  =  0.0\n",
      "ARAR, eps=0.0, like Wachter:  0  /  9871  =  0.0\n",
      "Wachter:  0  /  500  =  0.0\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  nan nan\n",
      "ARAR, eps=0.1, pgd:  nan nan\n",
      "ARAR, eps=0.05:  nan nan\n",
      "ARAR, eps=0.05, pgd:  nan nan\n",
      "ARAR, eps=0.0:  nan nan\n",
      "ARAR, eps=0.0, like Wachter:  nan nan\n",
      "Wachter:  nan nan\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  nan\n",
      "ARAR, eps=0.1, pgd:  nan\n",
      "ARAR, eps=0.05:  nan\n",
      "ARAR, eps=0.05, pgd:  nan\n",
      "ARAR, eps=0.0:  nan\n",
      "ARAR, eps=0.0, like Wachter:  nan\n",
      "Wachter:  nan\n",
      "#################################################################################################################\n",
      "######### model_type:  linear\n",
      "#################################################################################################################\n",
      "###### Dataset Name:  adult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.000 Lambda: 0.0016:  60%|██████    | 60/100 [00:21<00:14,  2.85it/s]\n",
      "Pct left: 0.000 Lambda: 0.0016:  60%|██████    | 60/100 [02:03<01:22,  2.06s/it]\n",
      "Pct left: 0.000 Lambda: 0.0027:  55%|█████▌    | 55/100 [00:19<00:15,  2.83it/s]\n",
      "Pct left: 0.000 Lambda: 0.0027:  55%|█████▌    | 55/100 [01:56<01:35,  2.11s/it]\n",
      "Pct left: 0.000 Lambda: 0.0042:  51%|█████     | 51/100 [00:18<00:18,  2.72it/s]\n",
      "Pct left: 0.000 Lambda: 0.0000:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "100%|██████████| 500/500 [00:19<00:00, 26.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  40211  /  40211  =  1.0\n",
      "ARAR, eps=0.1, pgd:  40211  /  40211  =  1.0\n",
      "ARAR, eps=0.05:  40211  /  40211  =  1.0\n",
      "ARAR, eps=0.05, pgd:  40211  /  40211  =  1.0\n",
      "ARAR, eps=0.0:  40211  /  40211  =  1.0\n",
      "ARAR, eps=0.0, like Wachter:  40211  /  40211  =  1.0\n",
      "Wachter:  499  /  500  =  0.998\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  1.0 1.0\n",
      "ARAR, eps=0.1, pgd:  1.0 1.0\n",
      "ARAR, eps=0.05:  1.0 0.3790753773842978\n",
      "ARAR, eps=0.05, pgd:  1.0 0.3808410633906145\n",
      "ARAR, eps=0.0:  1.0 0.20141254880505335\n",
      "ARAR, eps=0.0, like Wachter:  1.0 0.0\n",
      "Wachter:  1.0 0.0\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  1.0\n",
      "ARAR, eps=0.1, pgd:  1.0\n",
      "ARAR, eps=0.05:  0.99408066\n",
      "ARAR, eps=0.05, pgd:  0.9941327\n",
      "ARAR, eps=0.0:  0.84581006\n",
      "ARAR, eps=0.0, like Wachter:  0.6360904\n",
      "Wachter:  0.6150621\n",
      "###### Dataset Name:  compas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.000 Lambda: 0.0718:  24%|██▍       | 24/100 [00:05<00:17,  4.40it/s]\n",
      "Pct left: 0.000 Lambda: 0.0718:  24%|██▍       | 24/100 [00:25<01:19,  1.05s/it]\n",
      "Pct left: 0.000 Lambda: 0.0985:  21%|██        | 21/100 [00:04<00:16,  4.66it/s]\n",
      "Pct left: 0.000 Lambda: 0.0985:  21%|██        | 21/100 [00:22<01:23,  1.06s/it]\n",
      "Pct left: 0.000 Lambda: 0.1094:  20%|██        | 20/100 [00:04<00:16,  4.82it/s]\n",
      "Pct left: 0.000 Lambda: 0.0000:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "100%|██████████| 317/317 [00:04<00:00, 77.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  317  /  317  =  1.0\n",
      "ARAR, eps=0.1, pgd:  317  /  317  =  1.0\n",
      "ARAR, eps=0.05:  317  /  317  =  1.0\n",
      "ARAR, eps=0.05, pgd:  317  /  317  =  1.0\n",
      "ARAR, eps=0.0:  317  /  317  =  1.0\n",
      "ARAR, eps=0.0, like Wachter:  317  /  317  =  1.0\n",
      "Wachter:  317  /  317  =  1.0\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  1.0 1.0\n",
      "ARAR, eps=0.1, pgd:  1.0 1.0\n",
      "ARAR, eps=0.05:  1.0 0.5772870662460567\n",
      "ARAR, eps=0.05, pgd:  1.0 0.5772870662460567\n",
      "ARAR, eps=0.0:  1.0 0.5772870662460567\n",
      "ARAR, eps=0.0, like Wachter:  1.0 0.0\n",
      "Wachter:  1.0 0.0\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  1.0\n",
      "ARAR, eps=0.1, pgd:  1.0\n",
      "ARAR, eps=0.05:  0.972735\n",
      "ARAR, eps=0.05, pgd:  0.9728392\n",
      "ARAR, eps=0.0:  0.8986467\n",
      "ARAR, eps=0.0, like Wachter:  0.5940915\n",
      "Wachter:  0.59408516\n",
      "###### Dataset Name:  give_me_some_credit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.000 Lambda: 0.0087:  44%|████▍     | 44/100 [00:07<00:09,  5.63it/s]\n",
      "Pct left: 0.000 Lambda: 0.0087:  44%|████▍     | 44/100 [00:41<00:52,  1.07it/s]\n",
      "Pct left: 0.000 Lambda: 0.0133:  40%|████      | 40/100 [00:07<00:10,  5.60it/s]\n",
      "Pct left: 0.000 Lambda: 0.0133:  40%|████      | 40/100 [00:37<00:56,  1.06it/s]\n",
      "Pct left: 0.000 Lambda: 0.0225:  35%|███▌      | 35/100 [00:06<00:11,  5.61it/s]\n",
      "Pct left: 0.000 Lambda: 0.0000:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "100%|██████████| 500/500 [00:04<00:00, 119.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  909  /  909  =  1.0\n",
      "ARAR, eps=0.1, pgd:  909  /  909  =  1.0\n",
      "ARAR, eps=0.05:  909  /  909  =  1.0\n",
      "ARAR, eps=0.05, pgd:  909  /  909  =  1.0\n",
      "ARAR, eps=0.0:  909  /  909  =  1.0\n",
      "ARAR, eps=0.0, like Wachter:  909  /  909  =  1.0\n",
      "Wachter:  500  /  500  =  1.0\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  1.0 1.0\n",
      "ARAR, eps=0.1, pgd:  1.0 1.0\n",
      "ARAR, eps=0.05:  1.0 0.7546754675467546\n",
      "ARAR, eps=0.05, pgd:  1.0 0.7535753575357536\n",
      "ARAR, eps=0.0:  1.0 0.7392739273927392\n",
      "ARAR, eps=0.0, like Wachter:  1.0 0.0\n",
      "Wachter:  1.0 0.0\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  1.0\n",
      "ARAR, eps=0.1, pgd:  1.0\n",
      "ARAR, eps=0.05:  0.9965764\n",
      "ARAR, eps=0.05, pgd:  0.99677\n",
      "ARAR, eps=0.0:  0.9589967\n",
      "ARAR, eps=0.0, like Wachter:  0.64025635\n",
      "Wachter:  0.64366394\n",
      "###### Dataset Name:  heloc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.000 Lambda: 0.0005:  71%|███████   | 71/100 [00:12<00:05,  5.50it/s]\n",
      "Pct left: 0.000 Lambda: 0.0005:  72%|███████▏  | 72/100 [01:11<00:27,  1.01it/s]\n",
      "Pct left: 0.000 Lambda: 0.0008:  67%|██████▋   | 67/100 [00:12<00:06,  5.50it/s]\n",
      "Pct left: 0.000 Lambda: 0.0008:  67%|██████▋   | 67/100 [01:06<00:32,  1.01it/s]\n",
      "Pct left: 0.000 Lambda: 0.0012:  63%|██████▎   | 63/100 [00:11<00:06,  5.50it/s]\n",
      "Pct left: 0.000 Lambda: 0.0000:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 137.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  5094  /  5094  =  1.0\n",
      "ARAR, eps=0.1, pgd:  5094  /  5094  =  1.0\n",
      "ARAR, eps=0.05:  5094  /  5094  =  1.0\n",
      "ARAR, eps=0.05, pgd:  5094  /  5094  =  1.0\n",
      "ARAR, eps=0.0:  5094  /  5094  =  1.0\n",
      "ARAR, eps=0.0, like Wachter:  5094  /  5094  =  1.0\n",
      "Wachter:  500  /  500  =  1.0\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  1.0 1.0\n",
      "ARAR, eps=0.1, pgd:  1.0 0.9998036906164115\n",
      "ARAR, eps=0.05:  1.0 0.9167648213584609\n",
      "ARAR, eps=0.05, pgd:  1.0 0.9155869650569297\n",
      "ARAR, eps=0.0:  1.0 0.9110718492343934\n",
      "ARAR, eps=0.0, like Wachter:  1.0 0.0\n",
      "Wachter:  1.0 0.0\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  1.0\n",
      "ARAR, eps=0.1, pgd:  1.0\n",
      "ARAR, eps=0.05:  0.99993896\n",
      "ARAR, eps=0.05, pgd:  0.9999393\n",
      "ARAR, eps=0.0:  0.9951147\n",
      "ARAR, eps=0.0, like Wachter:  0.78642267\n",
      "Wachter:  0.782816\n"
     ]
    }
   ],
   "source": [
    "EPSILON_TEST = 0.1\n",
    "\n",
    "\n",
    "# Hyperparams ARAR\n",
    "LR = 0.1\n",
    "OUTER_ITERS = 100\n",
    "INNER_ITERS = 50\n",
    "\n",
    "\n",
    "num_test_factuals = 100000\n",
    "num_test_factuals_wachter = 500 # Wachter is much slower due to missing parallelism \n",
    "for model_type in [\"ann\", \"linear\"]:\n",
    "    print(\"#################################################################################################################\")\n",
    "    print(\"######### model_type: \", model_type)\n",
    "    print(\"#################################################################################################################\")\n",
    "    for data_name in [\"adult\", \"compas\", \"give_me_some_credit\", \"heloc\"]: # \"adult\"\n",
    "        print(\"###### Dataset Name: \", data_name)\n",
    "        data = OnlineCatalog(data_name)\n",
    "\n",
    "        model = MLModelCatalog(data, model_type, backend=\"pytorch\")\n",
    "        # get factuals\n",
    "        factuals = predict_negative_instances(model, data.df)\n",
    "        factuals = factuals.sample(frac=1, random_state=8912983) # Shuffle data for good measure (only needed for wachter, as we do not use the whole dataset)\n",
    "        test_factual = factuals.iloc[:num_test_factuals]\n",
    "\n",
    "        if len(test_factual) == 0:\n",
    "            print(\"No test factuals classified as the negative instance were found -> skipping this evaluation\")\n",
    "            continue\n",
    "\n",
    "        # Generate Counterfactuals\n",
    "        hyperparams = {'lr': LR, 'outer_iters': OUTER_ITERS, 'inner_iters': INNER_ITERS, 'lambd_init': 1.0, 'decay_rate': 0.9, 'y_target':1, 'binary_cat_features': True, 'epsilon':0.1}\n",
    "        cfs_arar_eps01 = ARAR(model, hyperparams).get_counterfactuals(test_factual).dropna()\n",
    "\n",
    "        hyperparams = {'inner_max_pgd': True, 'lr': LR, 'outer_iters': OUTER_ITERS, 'inner_iters': INNER_ITERS, 'lambd_init': 1.0, 'decay_rate': 0.9, 'y_target':1, 'binary_cat_features': True, 'epsilon':0.1}\n",
    "        cfs_arar_eps01_pgd = ARAR(model, hyperparams).get_counterfactuals(test_factual).dropna()\n",
    "\n",
    "        hyperparams = {'lr': LR, 'outer_iters': OUTER_ITERS, 'inner_iters': INNER_ITERS, 'lambd_init': 1.0, 'decay_rate': 0.9, 'y_target':1, 'binary_cat_features': True, 'epsilon':0.05}\n",
    "        cfs_arar_eps005 = ARAR(model, hyperparams).get_counterfactuals(test_factual).dropna()\n",
    "\n",
    "        hyperparams = {'inner_max_pgd': True, 'lr': LR, 'outer_iters': OUTER_ITERS, 'inner_iters': INNER_ITERS, 'lambd_init': 1.0, 'decay_rate': 0.9, 'y_target':1, 'binary_cat_features': True, 'epsilon':0.05}\n",
    "        cfs_arar_eps005_pgd = ARAR(model, hyperparams).get_counterfactuals(test_factual).dropna()\n",
    "\n",
    "        hyperparams = {'lr': LR, 'outer_iters': OUTER_ITERS, 'inner_iters': INNER_ITERS, 'lambd_init': 1.0, 'decay_rate': 0.9, 'y_target':1, 'binary_cat_features': True, 'epsilon':0.0}\n",
    "        cfs_arar_eps0 = ARAR(model, hyperparams).get_counterfactuals(test_factual).dropna()\n",
    "        \n",
    "        # ARAR with hyperparameters to match the ones that are used in Wachter -> obtains very similar results\n",
    "        hyperparams = {'y_target':1, 'binary_cat_features': True, 'epsilon':0.0,\n",
    "                        'lr': 0.01, # smaller learning rate\n",
    "                        'lambd_init': 0.0, # no l1-regularization on the delta\n",
    "                        'decay_rate': 1.0, \n",
    "                        'outer_iters': OUTER_ITERS, # 1000\n",
    "                        'inner_iters': INNER_ITERS,\n",
    "                        }\n",
    "        cfs_arar_eps0_like_wachter = ARAR(model, hyperparams).get_counterfactuals(test_factual).dropna()\n",
    "\n",
    "\n",
    "        hyperparams = {\"loss_type\": \"BCE\", \"binary_cat_features\": True, \"t_max_min\": 0.01, \"verbose_logging\": False}\n",
    "        cfs_wachter = recourse_catalog.Wachter(model, hyperparams).get_counterfactuals(test_factual[:num_test_factuals_wachter]).dropna()\n",
    "\n",
    "        print(\"### Number of counterfactuals found / Total number of factuals\")\n",
    "        print(\"ARAR, eps=0.1: \", len(cfs_arar_eps01), \" / \", len(test_factual), \" = \", len(cfs_arar_eps01) / len(test_factual))\n",
    "        print(\"ARAR, eps=0.1, pgd: \", len(cfs_arar_eps01_pgd), \" / \", len(test_factual), \" = \", len(cfs_arar_eps01_pgd) / len(test_factual))\n",
    "        print(\"ARAR, eps=0.05: \", len(cfs_arar_eps005), \" / \", len(test_factual), \" = \", len(cfs_arar_eps005) / len(test_factual))\n",
    "        print(\"ARAR, eps=0.05, pgd: \", len(cfs_arar_eps005_pgd), \" / \", len(test_factual), \" = \", len(cfs_arar_eps005_pgd) / len(test_factual))\n",
    "        print(\"ARAR, eps=0.0: \", len(cfs_arar_eps0), \" / \", len(test_factual), \" = \", len(cfs_arar_eps0) / len(test_factual))\n",
    "        print(\"ARAR, eps=0.0, like Wachter: \", len(cfs_arar_eps0_like_wachter), \" / \", len(test_factual), \" = \", len(cfs_arar_eps0_like_wachter) / len(test_factual))\n",
    "        print(\"Wachter: \", len(cfs_wachter), \" / \", len(test_factual[:num_test_factuals_wachter]), \" = \", len(cfs_wachter) / len(test_factual[:num_test_factuals_wachter]))\n",
    "\n",
    "        \n",
    "        # Generate perturbations with gradient\n",
    "        print(\"### predictions classified as target / predictions classified as target after perturbation with gradient\")\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_arar_eps01, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.1: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_arar_eps01_pgd, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.1, pgd: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_arar_eps005, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.05: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_arar_eps005_pgd, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.05, pgd: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_arar_eps0, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.0: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_arar_eps0_like_wachter, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.0, like Wachter: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_wachter, epsilon=EPSILON_TEST)\n",
    "        print(\"Wachter: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "\n",
    "        # generate random perturbations\n",
    "        print(\"### Proportion of classifications to target with random perturbations in epsilon ball: \")\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_arar_eps01, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.1: \", proportions.mean())\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_arar_eps01_pgd, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.1, pgd: \", proportions.mean())\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_arar_eps005, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.05: \", proportions.mean())\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_arar_eps005_pgd, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.05, pgd: \", proportions.mean())\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_arar_eps0, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.0: \", proportions.mean())\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_arar_eps0_like_wachter, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.0, like Wachter: \", proportions.mean())\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_wachter, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"Wachter: \", proportions.mean())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smaller LR, all else equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################################################################\n",
      "######### model_type:  ann\n",
      "#################################################################################################################\n",
      "###### Dataset Name:  adult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.993 Lambda: 0.0000: 100%|██████████| 100/100 [01:44<00:00,  1.05s/it]\n",
      "Pct left: 0.993 Lambda: 0.0000: 100%|██████████| 100/100 [10:08<00:00,  6.09s/it]\n",
      "Pct left: 0.821 Lambda: 0.0000: 100%|██████████| 100/100 [01:43<00:00,  1.04s/it]\n",
      "Pct left: 0.821 Lambda: 0.0000: 100%|██████████| 100/100 [10:06<00:00,  6.06s/it]\n",
      "Pct left: 0.613 Lambda: 0.0000: 100%|██████████| 100/100 [01:45<00:00,  1.05s/it]\n",
      "Pct left: 0.613 Lambda: 0.0000: 100%|██████████| 100/100 [01:45<00:00,  1.05s/it]\n",
      "100%|██████████| 500/500 [15:44<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  277  /  40325  =  0.006869187848729076\n",
      "ARAR, eps=0.1, pgd:  277  /  40325  =  0.006869187848729076\n",
      "ARAR, eps=0.05:  7216  /  40325  =  0.17894606323620582\n",
      "ARAR, eps=0.05, pgd:  7216  /  40325  =  0.17894606323620582\n",
      "ARAR, eps=0.0:  15621  /  40325  =  0.3873775573465592\n",
      "ARAR, eps=0.0, like Wachter:  15621  /  40325  =  0.3873775573465592\n",
      "Wachter:  203  /  500  =  0.406\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  1.0 1.0\n",
      "ARAR, eps=0.1, pgd:  1.0 1.0\n",
      "ARAR, eps=0.05:  1.0 0.0\n",
      "ARAR, eps=0.05, pgd:  1.0 0.0\n",
      "ARAR, eps=0.0:  1.0 0.0\n",
      "ARAR, eps=0.0, like Wachter:  1.0 0.0\n",
      "Wachter:  1.0 0.0\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  1.0\n",
      "ARAR, eps=0.1, pgd:  1.0\n",
      "ARAR, eps=0.05:  0.9749105\n",
      "ARAR, eps=0.05, pgd:  0.97506785\n",
      "ARAR, eps=0.0:  0.55173016\n",
      "ARAR, eps=0.0, like Wachter:  0.60618407\n",
      "Wachter:  0.59691626\n",
      "###### Dataset Name:  compas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.995 Lambda: 0.0000: 100%|██████████| 100/100 [00:30<00:00,  3.24it/s]\n",
      "Pct left: 0.995 Lambda: 0.0000: 100%|██████████| 100/100 [02:25<00:00,  1.45s/it]\n",
      "Pct left: 0.602 Lambda: 0.0000: 100%|██████████| 100/100 [00:30<00:00,  3.25it/s]\n",
      "Pct left: 0.602 Lambda: 0.0000: 100%|██████████| 100/100 [02:24<00:00,  1.45s/it]\n",
      "Pct left: 0.343 Lambda: 0.0000: 100%|██████████| 100/100 [00:30<00:00,  3.25it/s]\n",
      "Pct left: 0.343 Lambda: 0.0000: 100%|██████████| 100/100 [00:30<00:00,  3.26it/s]\n",
      "100%|██████████| 500/500 [07:04<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  4  /  800  =  0.005\n",
      "ARAR, eps=0.1, pgd:  4  /  800  =  0.005\n",
      "ARAR, eps=0.05:  318  /  800  =  0.3975\n",
      "ARAR, eps=0.05, pgd:  318  /  800  =  0.3975\n",
      "ARAR, eps=0.0:  526  /  800  =  0.6575\n",
      "ARAR, eps=0.0, like Wachter:  526  /  800  =  0.6575\n",
      "Wachter:  322  /  500  =  0.644\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  1.0 1.0\n",
      "ARAR, eps=0.1, pgd:  1.0 1.0\n",
      "ARAR, eps=0.05:  1.0 0.0\n",
      "ARAR, eps=0.05, pgd:  1.0 0.0\n",
      "ARAR, eps=0.0:  1.0 0.0\n",
      "ARAR, eps=0.0, like Wachter:  1.0 0.0\n",
      "Wachter:  1.0 0.0\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  1.0\n",
      "ARAR, eps=0.1, pgd:  1.0\n",
      "ARAR, eps=0.05:  0.9018931\n",
      "ARAR, eps=0.05, pgd:  0.9027295\n",
      "ARAR, eps=0.0:  0.5365095\n",
      "ARAR, eps=0.0, like Wachter:  0.59002095\n",
      "Wachter:  0.5917857\n",
      "###### Dataset Name:  give_me_some_credit\n",
      "No test factuals classified as the negative instance were found -> skipping this evaluation\n",
      "###### Dataset Name:  heloc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 1.000 Lambda: 0.0000: 100%|██████████| 100/100 [00:39<00:00,  2.51it/s]\n",
      "Pct left: 1.000 Lambda: 0.0000: 100%|██████████| 100/100 [03:45<00:00,  2.26s/it]\n",
      "Pct left: 1.000 Lambda: 0.0000: 100%|██████████| 100/100 [00:39<00:00,  2.50it/s]\n",
      "Pct left: 1.000 Lambda: 0.0000: 100%|██████████| 100/100 [03:46<00:00,  2.26s/it]\n",
      "Pct left: 1.000 Lambda: 0.0000: 100%|██████████| 100/100 [00:40<00:00,  2.49it/s]\n",
      "Pct left: 1.000 Lambda: 0.0000: 100%|██████████| 100/100 [00:40<00:00,  2.50it/s]\n",
      "100%|██████████| 500/500 [15:27<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  0  /  9871  =  0.0\n",
      "ARAR, eps=0.1, pgd:  0  /  9871  =  0.0\n",
      "ARAR, eps=0.05:  0  /  9871  =  0.0\n",
      "ARAR, eps=0.05, pgd:  0  /  9871  =  0.0\n",
      "ARAR, eps=0.0:  0  /  9871  =  0.0\n",
      "ARAR, eps=0.0, like Wachter:  0  /  9871  =  0.0\n",
      "Wachter:  0  /  500  =  0.0\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  nan nan\n",
      "ARAR, eps=0.1, pgd:  nan nan\n",
      "ARAR, eps=0.05:  nan nan\n",
      "ARAR, eps=0.05, pgd:  nan nan\n",
      "ARAR, eps=0.0:  nan nan\n",
      "ARAR, eps=0.0, like Wachter:  nan nan\n",
      "Wachter:  nan nan\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  nan\n",
      "ARAR, eps=0.1, pgd:  nan\n",
      "ARAR, eps=0.05:  nan\n",
      "ARAR, eps=0.05, pgd:  nan\n",
      "ARAR, eps=0.0:  nan\n",
      "ARAR, eps=0.0, like Wachter:  nan\n",
      "Wachter:  nan\n",
      "#################################################################################################################\n",
      "######### model_type:  linear\n",
      "#################################################################################################################\n",
      "###### Dataset Name:  adult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.000 Lambda: 0.0005:  72%|███████▏  | 72/100 [00:27<00:10,  2.66it/s]\n",
      "Pct left: 0.000 Lambda: 0.0005:  72%|███████▏  | 72/100 [02:36<01:00,  2.17s/it]\n",
      "Pct left: 0.000 Lambda: 0.0010:  65%|██████▌   | 65/100 [00:24<00:13,  2.64it/s]\n",
      "Pct left: 0.000 Lambda: 0.0010:  65%|██████▌   | 65/100 [02:21<01:16,  2.18s/it]\n",
      "Pct left: 0.000 Lambda: 0.0018:  59%|█████▉    | 59/100 [00:22<00:15,  2.63it/s]\n",
      "Pct left: 0.000 Lambda: 0.0000:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "100%|██████████| 500/500 [00:19<00:00, 25.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  40211  /  40211  =  1.0\n",
      "ARAR, eps=0.1, pgd:  40211  /  40211  =  1.0\n",
      "ARAR, eps=0.05:  40211  /  40211  =  1.0\n",
      "ARAR, eps=0.05, pgd:  40211  /  40211  =  1.0\n",
      "ARAR, eps=0.0:  40211  /  40211  =  1.0\n",
      "ARAR, eps=0.0, like Wachter:  40211  /  40211  =  1.0\n",
      "Wachter:  499  /  500  =  0.998\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  1.0 1.0\n",
      "ARAR, eps=0.1, pgd:  1.0 1.0\n",
      "ARAR, eps=0.05:  1.0 0.0\n",
      "ARAR, eps=0.05, pgd:  1.0 0.0\n",
      "ARAR, eps=0.0:  1.0 0.0\n",
      "ARAR, eps=0.0, like Wachter:  1.0 0.0\n",
      "Wachter:  1.0 0.0\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  1.0\n",
      "ARAR, eps=0.1, pgd:  1.0\n",
      "ARAR, eps=0.05:  0.9744845\n",
      "ARAR, eps=0.05, pgd:  0.97445047\n",
      "ARAR, eps=0.0:  0.568624\n",
      "ARAR, eps=0.0, like Wachter:  0.6360904\n",
      "Wachter:  0.6150621\n",
      "###### Dataset Name:  compas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.000 Lambda: 0.0471:  28%|██▊       | 28/100 [00:05<00:14,  4.90it/s]\n",
      "Pct left: 0.000 Lambda: 0.0471:  28%|██▊       | 28/100 [00:28<01:13,  1.02s/it]\n",
      "Pct left: 0.000 Lambda: 0.0581:  26%|██▌       | 26/100 [00:05<00:15,  4.92it/s]\n",
      "Pct left: 0.000 Lambda: 0.0581:  26%|██▌       | 26/100 [00:26<01:16,  1.03s/it]\n",
      "Pct left: 0.000 Lambda: 0.0718:  24%|██▍       | 24/100 [00:04<00:15,  4.91it/s]\n",
      "Pct left: 0.000 Lambda: 0.0000:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "100%|██████████| 317/317 [00:04<00:00, 77.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  317  /  317  =  1.0\n",
      "ARAR, eps=0.1, pgd:  317  /  317  =  1.0\n",
      "ARAR, eps=0.05:  317  /  317  =  1.0\n",
      "ARAR, eps=0.05, pgd:  317  /  317  =  1.0\n",
      "ARAR, eps=0.0:  317  /  317  =  1.0\n",
      "ARAR, eps=0.0, like Wachter:  317  /  317  =  1.0\n",
      "Wachter:  317  /  317  =  1.0\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  1.0 1.0\n",
      "ARAR, eps=0.1, pgd:  1.0 1.0\n",
      "ARAR, eps=0.05:  1.0 0.0\n",
      "ARAR, eps=0.05, pgd:  1.0 0.0\n",
      "ARAR, eps=0.0:  1.0 0.0\n",
      "ARAR, eps=0.0, like Wachter:  1.0 0.0\n",
      "Wachter:  1.0 0.0\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  1.0\n",
      "ARAR, eps=0.1, pgd:  1.0\n",
      "ARAR, eps=0.05:  0.8952524\n",
      "ARAR, eps=0.05, pgd:  0.89594644\n",
      "ARAR, eps=0.0:  0.51942587\n",
      "ARAR, eps=0.0, like Wachter:  0.5940915\n",
      "Wachter:  0.59408516\n",
      "###### Dataset Name:  give_me_some_credit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.000 Lambda: 0.0046:  50%|█████     | 50/100 [00:08<00:08,  5.64it/s]\n",
      "Pct left: 0.000 Lambda: 0.0046:  50%|█████     | 50/100 [00:45<00:45,  1.10it/s]\n",
      "Pct left: 0.000 Lambda: 0.0079:  45%|████▌     | 45/100 [00:07<00:09,  5.66it/s]\n",
      "Pct left: 0.000 Lambda: 0.0079:  45%|████▌     | 45/100 [00:41<00:50,  1.09it/s]\n",
      "Pct left: 0.000 Lambda: 0.0133:  40%|████      | 40/100 [00:07<00:10,  5.66it/s]\n",
      "Pct left: 0.000 Lambda: 0.0000:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 129.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  909  /  909  =  1.0\n",
      "ARAR, eps=0.1, pgd:  909  /  909  =  1.0\n",
      "ARAR, eps=0.05:  909  /  909  =  1.0\n",
      "ARAR, eps=0.05, pgd:  909  /  909  =  1.0\n",
      "ARAR, eps=0.0:  909  /  909  =  1.0\n",
      "ARAR, eps=0.0, like Wachter:  909  /  909  =  1.0\n",
      "Wachter:  500  /  500  =  1.0\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  1.0 1.0\n",
      "ARAR, eps=0.1, pgd:  1.0 1.0\n",
      "ARAR, eps=0.05:  1.0 0.0\n",
      "ARAR, eps=0.05, pgd:  1.0 0.0\n",
      "ARAR, eps=0.0:  1.0 0.0\n",
      "ARAR, eps=0.0, like Wachter:  1.0 0.0\n",
      "Wachter:  1.0 0.0\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  1.0\n",
      "ARAR, eps=0.1, pgd:  1.0\n",
      "ARAR, eps=0.05:  0.9497096\n",
      "ARAR, eps=0.05, pgd:  0.9498801\n",
      "ARAR, eps=0.0:  0.5461155\n",
      "ARAR, eps=0.0, like Wachter:  0.64025635\n",
      "Wachter:  0.64366394\n",
      "###### Dataset Name:  heloc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pct left: 0.000 Lambda: 0.0001:  86%|████████▌ | 86/100 [00:15<00:02,  5.66it/s]\n",
      "Pct left: 0.000 Lambda: 0.0001:  86%|████████▌ | 86/100 [01:21<00:13,  1.05it/s]\n",
      "Pct left: 0.000 Lambda: 0.0002:  80%|████████  | 80/100 [00:14<00:03,  5.67it/s]\n",
      "Pct left: 0.000 Lambda: 0.0002:  80%|████████  | 80/100 [01:15<00:18,  1.05it/s]\n",
      "Pct left: 0.000 Lambda: 0.0004:  74%|███████▍  | 74/100 [00:13<00:04,  5.62it/s]\n",
      "Pct left: 0.000 Lambda: 0.0000:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 141.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of counterfactuals found / Total number of factuals\n",
      "ARAR, eps=0.1:  5094  /  5094  =  1.0\n",
      "ARAR, eps=0.1, pgd:  5094  /  5094  =  1.0\n",
      "ARAR, eps=0.05:  5094  /  5094  =  1.0\n",
      "ARAR, eps=0.05, pgd:  5094  /  5094  =  1.0\n",
      "ARAR, eps=0.0:  5094  /  5094  =  1.0\n",
      "ARAR, eps=0.0, like Wachter:  5094  /  5094  =  1.0\n",
      "Wachter:  500  /  500  =  1.0\n",
      "### predictions classified as target / predictions classified as target after perturbation with gradient\n",
      "ARAR, eps=0.1:  1.0 1.0\n",
      "ARAR, eps=0.1, pgd:  1.0 1.0\n",
      "ARAR, eps=0.05:  1.0 0.0\n",
      "ARAR, eps=0.05, pgd:  1.0 0.0\n",
      "ARAR, eps=0.0:  1.0 0.0\n",
      "ARAR, eps=0.0, like Wachter:  1.0 0.0\n",
      "Wachter:  1.0 0.0\n",
      "### Proportion of classifications to target with random perturbations in epsilon ball: \n",
      "ARAR, eps=0.1:  1.0\n",
      "ARAR, eps=0.1, pgd:  1.0\n",
      "ARAR, eps=0.05:  0.9932804\n",
      "ARAR, eps=0.05, pgd:  0.99336797\n",
      "ARAR, eps=0.0:  0.5646785\n",
      "ARAR, eps=0.0, like Wachter:  0.78642267\n",
      "Wachter:  0.782816\n"
     ]
    }
   ],
   "source": [
    "EPSILON_TEST = 0.1\n",
    "\n",
    "\n",
    "# Hyperparams ARAR\n",
    "LR = 0.01\n",
    "OUTER_ITERS = 100\n",
    "INNER_ITERS = 50\n",
    "\n",
    "\n",
    "num_test_factuals = 100000\n",
    "num_test_factuals_wachter = 500 # Wachter is much slower due to missing parallelism \n",
    "for model_type in [\"ann\", \"linear\"]:\n",
    "    print(\"#################################################################################################################\")\n",
    "    print(\"######### model_type: \", model_type)\n",
    "    print(\"#################################################################################################################\")\n",
    "    for data_name in [\"adult\", \"compas\", \"give_me_some_credit\", \"heloc\"]: # \"adult\"\n",
    "        print(\"###### Dataset Name: \", data_name)\n",
    "        data = OnlineCatalog(data_name)\n",
    "\n",
    "        model = MLModelCatalog(data, model_type, backend=\"pytorch\")\n",
    "        # get factuals\n",
    "        factuals = predict_negative_instances(model, data.df)\n",
    "        factuals = factuals.sample(frac=1, random_state=8912983) # Shuffle data for good measure (only needed for wachter, as we do not use the whole dataset)\n",
    "        test_factual = factuals.iloc[:num_test_factuals]\n",
    "\n",
    "        if len(test_factual) == 0:\n",
    "            print(\"No test factuals classified as the negative instance were found -> skipping this evaluation\")\n",
    "            continue\n",
    "\n",
    "        # Generate Counterfactuals\n",
    "        hyperparams = {'lr': LR, 'outer_iters': OUTER_ITERS, 'inner_iters': INNER_ITERS, 'lambd_init': 1.0, 'decay_rate': 0.9, 'y_target':1, 'binary_cat_features': True, 'epsilon':0.1}\n",
    "        cfs_arar_eps01 = ARAR(model, hyperparams).get_counterfactuals(test_factual).dropna()\n",
    "\n",
    "        hyperparams = {'inner_max_pgd': True, 'lr': LR, 'outer_iters': OUTER_ITERS, 'inner_iters': INNER_ITERS, 'lambd_init': 1.0, 'decay_rate': 0.9, 'y_target':1, 'binary_cat_features': True, 'epsilon':0.1}\n",
    "        cfs_arar_eps01_pgd = ARAR(model, hyperparams).get_counterfactuals(test_factual).dropna()\n",
    "\n",
    "        hyperparams = {'lr': LR, 'outer_iters': OUTER_ITERS, 'inner_iters': INNER_ITERS, 'lambd_init': 1.0, 'decay_rate': 0.9, 'y_target':1, 'binary_cat_features': True, 'epsilon':0.05}\n",
    "        cfs_arar_eps005 = ARAR(model, hyperparams).get_counterfactuals(test_factual).dropna()\n",
    "\n",
    "        hyperparams = {'inner_max_pgd': True, 'lr': LR, 'outer_iters': OUTER_ITERS, 'inner_iters': INNER_ITERS, 'lambd_init': 1.0, 'decay_rate': 0.9, 'y_target':1, 'binary_cat_features': True, 'epsilon':0.05}\n",
    "        cfs_arar_eps005_pgd = ARAR(model, hyperparams).get_counterfactuals(test_factual).dropna()\n",
    "\n",
    "        hyperparams = {'lr': LR, 'outer_iters': OUTER_ITERS, 'inner_iters': INNER_ITERS, 'lambd_init': 1.0, 'decay_rate': 0.9, 'y_target':1, 'binary_cat_features': True, 'epsilon':0.0}\n",
    "        cfs_arar_eps0 = ARAR(model, hyperparams).get_counterfactuals(test_factual).dropna()\n",
    "        \n",
    "        # ARAR with hyperparameters to match the ones that are used in Wachter -> obtains very similar results\n",
    "        hyperparams = {'y_target':1, 'binary_cat_features': True, 'epsilon':0.0,\n",
    "                        'lr': 0.01, # smaller learning rate\n",
    "                        'lambd_init': 0.0, # no l1-regularization on the delta\n",
    "                        'decay_rate': 1.0, \n",
    "                        'outer_iters': OUTER_ITERS, # 1000\n",
    "                        'inner_iters': INNER_ITERS,\n",
    "                        }\n",
    "        cfs_arar_eps0_like_wachter = ARAR(model, hyperparams).get_counterfactuals(test_factual).dropna()\n",
    "\n",
    "\n",
    "        hyperparams = {\"loss_type\": \"BCE\", \"binary_cat_features\": True, \"t_max_min\": 0.01, \"verbose_logging\": False}\n",
    "        cfs_wachter = recourse_catalog.Wachter(model, hyperparams).get_counterfactuals(test_factual[:num_test_factuals_wachter]).dropna()\n",
    "\n",
    "        print(\"### Number of counterfactuals found / Total number of factuals\")\n",
    "        print(\"ARAR, eps=0.1: \", len(cfs_arar_eps01), \" / \", len(test_factual), \" = \", len(cfs_arar_eps01) / len(test_factual))\n",
    "        print(\"ARAR, eps=0.1, pgd: \", len(cfs_arar_eps01_pgd), \" / \", len(test_factual), \" = \", len(cfs_arar_eps01_pgd) / len(test_factual))\n",
    "        print(\"ARAR, eps=0.05: \", len(cfs_arar_eps005), \" / \", len(test_factual), \" = \", len(cfs_arar_eps005) / len(test_factual))\n",
    "        print(\"ARAR, eps=0.05, pgd: \", len(cfs_arar_eps005_pgd), \" / \", len(test_factual), \" = \", len(cfs_arar_eps005_pgd) / len(test_factual))\n",
    "        print(\"ARAR, eps=0.0: \", len(cfs_arar_eps0), \" / \", len(test_factual), \" = \", len(cfs_arar_eps0) / len(test_factual))\n",
    "        print(\"ARAR, eps=0.0, like Wachter: \", len(cfs_arar_eps0_like_wachter), \" / \", len(test_factual), \" = \", len(cfs_arar_eps0_like_wachter) / len(test_factual))\n",
    "        print(\"Wachter: \", len(cfs_wachter), \" / \", len(test_factual[:num_test_factuals_wachter]), \" = \", len(cfs_wachter) / len(test_factual[:num_test_factuals_wachter]))\n",
    "\n",
    "        \n",
    "        # Generate perturbations with gradient\n",
    "        print(\"### predictions classified as target / predictions classified as target after perturbation with gradient\")\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_arar_eps01, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.1: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_arar_eps01_pgd, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.1, pgd: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_arar_eps005, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.05: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_arar_eps005_pgd, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.05, pgd: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_arar_eps0, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.0: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_arar_eps0_like_wachter, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.0, like Wachter: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "        x_pertb, preds, preds_pertb = experiment_generate_perturbations_gradient(model, cfs_wachter, epsilon=EPSILON_TEST)\n",
    "        print(\"Wachter: \", (preds >= 0.5).mean(), (preds_pertb >= 0.5).mean())\n",
    "\n",
    "        # generate random perturbations\n",
    "        print(\"### Proportion of classifications to target with random perturbations in epsilon ball: \")\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_arar_eps01, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.1: \", proportions.mean())\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_arar_eps01_pgd, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.1, pgd: \", proportions.mean())\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_arar_eps005, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.05: \", proportions.mean())\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_arar_eps005_pgd, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.05, pgd: \", proportions.mean())\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_arar_eps0, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.0: \", proportions.mean())\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_arar_eps0_like_wachter, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"ARAR, eps=0.0, like Wachter: \", proportions.mean())\n",
    "        proportions = experiment_generate_perturbations_random(model, cfs_wachter, n_samples=1000, epsilon=EPSILON_TEST)\n",
    "        print(\"Wachter: \", proportions.mean())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CARLA-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74f680e2a813fd0c076c0456d1a2dbce1a03c09078f2bb9c70da05e8a6c7ef12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
